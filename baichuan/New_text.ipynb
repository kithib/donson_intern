{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer,Pipeline \n",
    "from transformers.generation.utils import GenerationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(badwords = []):\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        \"/data/tds/Baichuan2/Baichuan2-13B-Chat\",\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"cuda:0\",\n",
    "        trust_remote_code=True,\n",
    "    )\n",
    "    model.generation_config = GenerationConfig.from_pretrained(\n",
    "        \"/data/tds/Baichuan2/Baichuan2-13B-Chat\",\n",
    "        temperature=0.8,\n",
    "        no_repeat_ngram_size=8,\n",
    "        bad_words_ids = badwords\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        \"/data/tds/Baichuan2/Baichuan2-13B-Chat\",\n",
    "        use_fast=False,\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    print(model.generation_config)\n",
    "    return model, tokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "        \"/data/tds/Baichuan2/Baichuan2-13B-Chat\",\n",
    "        use_fast=False,\n",
    "        trust_remote_code=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "019b136d856a4d7d98fa08b15becc317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenerationConfig {\n",
      "  \"assistant_token_id\": 196,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      4547\n",
      "    ],\n",
      "    [\n",
      "      10108\n",
      "    ],\n",
      "    [\n",
      "      3258\n",
      "    ],\n",
      "    [\n",
      "      9969\n",
      "    ],\n",
      "    [\n",
      "      2534\n",
      "    ],\n",
      "    [\n",
      "      14748\n",
      "    ],\n",
      "    [\n",
      "      37425\n",
      "    ],\n",
      "    [\n",
      "      50515\n",
      "    ],\n",
      "    [\n",
      "      10839\n",
      "    ],\n",
      "    [\n",
      "      11395\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 1,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"max_new_tokens\": 2048,\n",
      "  \"no_repeat_ngram_size\": 8,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"repetition_penalty\": 1.05,\n",
      "  \"temperature\": 0.8,\n",
      "  \"top_k\": 5,\n",
      "  \"top_p\": 0.85,\n",
      "  \"transformers_version\": \"4.33.2\",\n",
      "  \"user_token_id\": 195\n",
      "}\n",
      "\n",
      "GenerationConfig {\n",
      "  \"assistant_token_id\": 196,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      4547\n",
      "    ],\n",
      "    [\n",
      "      10108\n",
      "    ],\n",
      "    [\n",
      "      3258\n",
      "    ],\n",
      "    [\n",
      "      9969\n",
      "    ],\n",
      "    [\n",
      "      2534\n",
      "    ],\n",
      "    [\n",
      "      14748\n",
      "    ],\n",
      "    [\n",
      "      37425\n",
      "    ],\n",
      "    [\n",
      "      50515\n",
      "    ],\n",
      "    [\n",
      "      10839\n",
      "    ],\n",
      "    [\n",
      "      11395\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 1,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"max_new_tokens\": 2048,\n",
      "  \"no_repeat_ngram_size\": 8,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"repetition_penalty\": 1.05,\n",
      "  \"temperature\": 0.8,\n",
      "  \"top_k\": 5,\n",
      "  \"top_p\": 0.85,\n",
      "  \"transformers_version\": \"4.33.2\",\n",
      "  \"user_token_id\": 195\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "connective_words = ['é¦–å…ˆ', 'å…¶æ¬¡', 'ç„¶åŽ', 'æŽ¥ç€', 'æœ€åŽ', 'æ€»ä¹‹','æ€»çš„æ¥è¯´','æ€»è€Œè¨€ä¹‹','ä¸€æ–¹é¢','å¦ä¸€æ–¹é¢']\n",
    "badwords = tokenizer(connective_words, add_special_tokens=False).input_ids\n",
    "model,tokenizer = init_model(badwords=badwords)\n",
    "print(model.generation_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŒŸ æ˜Žæ˜Ÿä»¿å¦†æ•™ç¨‹ï¼šæ¨¡ä»¿èµµä¸½é¢–çš„ç”œç¾Žå¦†å®¹ ðŸŒŸ\n",
      "\n",
      "ðŸŽ‰ å¤§å®¶å¥½ï¼æˆ‘æ˜¯ä½ ä»¬çš„ç¾Žå¦†åšä¸»å°ç¾Žï¼Œä»Šå¤©æˆ‘å°†æ•™å¤§å®¶å¦‚ä½•æ¨¡ä»¿èµµä¸½é¢–çš„ç”œç¾Žå¦†å®¹ã€‚æŽ¥ä¸‹æ¥è®©æˆ‘ä»¬å¼€å§‹å§ï¼\n",
      "\n",
      "1ï¸âƒ£ åº•å¦†ï¼šç¬¬ä¸€æ­¥æ˜¯æ‰“é€ å®Œç¾Žçš„åº•å¦†ã€‚æˆ‘ä»¬éœ€è¦é€‰æ‹©ä¸€æ¬¾é€‚åˆæˆ‘ä»¬çš„ç²‰åº•æ¶²ï¼Œæˆ‘ç”¨çš„æ˜¯é›…è¯—å…°é»›çš„åŒå¤´ç²‰åº•æ¶²ï¼Œå®ƒå¯ä»¥æ‰“é€ å‡ºè‡ªç„¶çš„è‚¤è‰²ã€‚ç”¨åŒ–å¦†æµ·ç»µå‡åŒ€æ¶‚æŠ¹åœ¨è„¸ä¸Šï¼Œé®ç›–ç‘•ç–µå’Œå‡åŒ€è‚¤è‰²ã€‚\n",
      "\n",
      "2ï¸âƒ£ é®ç‘•ï¼šæŽ¥ä¸‹æ¥æˆ‘ä»¬è¦ç”¨é®ç‘•è†é®ç›–é»‘çœ¼åœˆå’Œç—˜å°ã€‚æˆ‘ç”¨çš„æ˜¯NARSçš„é®ç‘•è†ï¼Œå®ƒéžå¸¸é€‚åˆé®ç›–ç‘•ç–µã€‚ç”¨é®ç‘•åˆ·è˜¸å–é€‚é‡é®ç‘•è†ï¼Œç‚¹æ‹åœ¨éœ€è¦é®ç›–çš„åœ°æ–¹ï¼Œç„¶åŽç”¨æ‰‹æŒ‡è½»è½»æ‹æ‰“ï¼Œè®©é®ç‘•è†æ›´å¥½åœ°èžå…¥çš®è‚¤ã€‚\n",
      "\n",
      "3ï¸âƒ£ çœ¼å¦†ï¼šæŽ¥ä¸‹æ¥æˆ‘ä»¬å¼€å§‹ç”»çœ¼å¦†ã€‚å…ˆç”¨çœ¼å½±åˆ·è˜¸å–ä¸€äº›å¤§åœ°è‰²çœ¼å½±ï¼Œæ‰“åº•æ•´ä¸ªçœ¼çš®ã€‚ç„¶åŽç”¨ç²‰è‰²çœ¼å½±åœ¨çœ¼çš®ä¸­å¤®æ™•æŸ“ï¼Œå¢žåŠ çœ¼éƒ¨ç«‹ä½“æ„Ÿã€‚å†ç”¨äº®ç‰‡çœ¼å½±åœ¨çœ¼çš®ä¸­å¤®å’Œçœ¼å¤´å¤„ç‚¹ç¼€ï¼Œå¢žåŠ çœ¼éƒ¨é—ªäº®æ„Ÿã€‚æœ€åŽæ˜¯ç”»çœ¼çº¿ï¼Œæˆ‘é€‰æ‹©çš„æ˜¯æ£•è‰²çš„çœ¼çº¿ç¬”ï¼Œè®©å®ƒæ›´è‡ªç„¶ã€‚\n",
      "\n",
      "4ï¸âƒ£ ç«æ¯›ï¼šä¸ºäº†è®©çœ¼ç›æ›´æœ‰ç¥žï¼Œæˆ‘ä»¬éœ€è¦è´´åŒçœ¼çš®è´´å’Œåˆ·ç«æ¯›ã€‚æˆ‘å…ˆè´´ä¸ŠåŒçœ¼çš®è´´ï¼Œç„¶åŽç”¨ç«æ¯›å¤¹å¤¹ç¿˜ç«æ¯›ï¼Œæœ€åŽå†åˆ·ä¸Šæµ“å¯†çš„ç«æ¯›è†ã€‚\n",
      "\n",
      "5ï¸âƒ£ è…®çº¢ï¼šä¸ºäº†è®©è„¸éƒ¨æ›´æœ‰æ°”è‰²ï¼Œæˆ‘ä»¬éœ€è¦æ‰“è…®çº¢ã€‚æˆ‘ç”¨çš„æ˜¯NARSçš„è…®çº¢ï¼Œé¢œè‰²éžå¸¸è‡ªç„¶ã€‚å°†è…®çº¢ä»Žé¢§éª¨å¤„å‘å¤ªé˜³ç©´æ–¹å‘è½»è½»æ‰«åŽ»ï¼Œçœ‹åˆ°æ²¡æœ‰ï¼Ÿè„¸éƒ¨ç«‹åˆ»æœ‰äº†çº¢æ¶¦çš„æ„Ÿè§‰ï¼\n",
      "\n",
      "6ï¸âƒ£ å”‡å¦†ï¼šæœ€åŽæ˜¯å”‡å¦†éƒ¨åˆ†ï¼Œæˆ‘ç”¨çš„æ˜¯YSLçš„æ°´å…‰å”‡é‡‰ï¼Œé¢œè‰²éžå¸¸ç”œç¾Žã€‚å…ˆå°†å”‡éƒ¨ä¿æ¹¿åšå¥½ï¼Œç„¶åŽå°†å”‡é‡‰å‡åŒ€æ¶‚æŠ¹åœ¨å”‡éƒ¨ï¼Œæœ€åŽå†è½»è½»æŠ¿ä¸€ä¸‹ï¼Œè®©å”‡é‡‰æ›´åŠ æœå¸–ã€‚\n",
      "\n",
      "ðŸ’– çŽ°åœ¨ï¼Œä¸€ä¸ªç”œç¾Žçš„èµµä¸½é¢–ä»¿å¦†å°±å®Œæˆå•¦ï¼å¸Œæœ›å¤§å®¶å–œæ¬¢è¿™ä¸ªæ•™ç¨‹ï¼Œä¹Ÿæ¬¢è¿Žå¤§å®¶ç§ä¿¡æˆ‘äº¤æµç¾Žå¦†å¿ƒå¾—å“¦~çˆ±ä½ ä»¬ï¼\n"
     ]
    }
   ],
   "source": [
    "prompt =  \"\"\"\n",
    "ä½ æ˜¯ä¸€åå°çº¢ä¹¦ä¸Šçš„ ç¾Žå¦† åšä¸»ï¼Œè¯·ä½ åˆ¶ä½œä¸€ç¯‡ æ˜Žæ˜Ÿä»¿å¦† çš„æ•™ç¨‹åˆ†äº«ã€‚\n",
    "\n",
    "æ•™ç¨‹æ­¥éª¤ï¼š è‡³å°‘5ä¸ªæ­¥éª¤ \n",
    "\n",
    "äº§å“æ¸…å•ï¼š åˆ—å‡ºæ‰€ä½¿ç”¨çš„ä¸»è¦äº§å“ \n",
    "\n",
    "å¹³å°æ–‡é£Žï¼š å°çº¢ä¹¦ ã€‚\n",
    "\n",
    "æ–‡æ¡ˆè¦æ±‚ï¼š é€»è¾‘æ¸…æ™°ï¼Œå¯ä»¥é€‚å½“åŠ ä¸€äº›è¡¨æƒ…ç¬¦å·ã€‚\n",
    "\"\"\"\n",
    "messages = []\n",
    "messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "response = model.chat(tokenizer, messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"NewPrompt.xlsx\",header=None)\n",
    "df = df.assign(round0_ans = None , round1_ans = None)\n",
    "str(df.iloc[0,1]) == \"nan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prompt_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m100\u001b[39m):\n\u001b[1;32m      2\u001b[0m     messages \u001b[39m=\u001b[39m []\n\u001b[0;32m----> 3\u001b[0m     messages\u001b[39m.\u001b[39mappend({\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39muser\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: prompt_list[\u001b[39m6\u001b[39m]})\n\u001b[1;32m      4\u001b[0m     response \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mchat(tokenizer, messages)\n\u001b[1;32m      5\u001b[0m     \u001b[39mprint\u001b[39m(prompt_list[\u001b[39m6\u001b[39m],response)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prompt_list' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(len(df)):\n",
    "    messages = []\n",
    "    if str(df.iloc[i,1])  == \"nan\":\n",
    "        messages.append({\"role\": \"user\", \"content\": df.iloc[i,0]})\n",
    "        response = model.chat(tokenizer, messages)\n",
    "        df.iloc[i,2] = response\n",
    "    else:\n",
    "        messages = [history]\n",
    "        messages.append({\"role\": \"user\", \"content\": df.iloc[i,1]})\n",
    "        response,history = model.chat(tokenizer, messages)\n",
    "        df.iloc[i,3] = response\n",
    "df.to_excel(\"NewPromptEval.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
