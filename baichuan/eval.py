import torch
import time
import pandas as pd
import numpy as np
from transformers import AutoModelForCausalLM, AutoTokenizer
from transformers.generation.utils import GenerationConfig

#åŠ è½½æ¨¡å‹
def init_model():
    model = AutoModelForCausalLM.from_pretrained(
        "/data/tds/Baichuan2/Baichuan2-13B-Chat",
        torch_dtype=torch.float16,
        device_map="cuda:0",
        trust_remote_code=True
    )
    model.generation_config = GenerationConfig.from_pretrained(
        "/data/tds/Baichuan2/Baichuan2-13B-Chat"
    )
    tokenizer = AutoTokenizer.from_pretrained(
        "/data/tds/Baichuan2/Baichuan2-13B-Chat",
        use_fast=False,
        trust_remote_code=True
    )
    return model, tokenizer
model, tokenizer = init_model()

def init_model_withParamater():
    model = AutoModelForCausalLM.from_pretrained(
        "/data/tds/Baichuan2/Baichuan2-13B-Chat",
        torch_dtype=torch.float16,
        device_map="cuda:0",
        trust_remote_code=True,
    )
    model.generation_config = GenerationConfig.from_pretrained(
        "/data/tds/Baichuan2/Baichuan2-13B-Chat",
        do_sample=True, 
        top_p=8, 
        temperature=1.2,
        repetition_penalty = 1.1,
        num_beams = 2,
        early_stopping = True,
        no_repeat_ngram_size=3
    )
    tokenizer = AutoTokenizer.from_pretrained(
        "/data/tds/Baichuan2/Baichuan2-13B-Chat",
        use_fast=False,
        trust_remote_code=True
    )
    return model, tokenizer
model_withParamater, tokenizer_withParamater = init_model_withParamater()

#åŠ è½½æ•°æ®

def duplicate_rows(df, n):  
    # åˆ›å»ºä¸€ä¸ªæ–°çš„ç©ºDataFrame  
    new_df = pd.DataFrame()  
      
    # éå†dfçš„æ¯ä¸€è¡Œ  
    for index, row in df.iterrows(): 
        tem_df = df.iloc[index:index+1]  
        for j in range(n):
            new_df = pd.concat([new_df,tem_df]) 
    return new_df



df = pd.read_csv("/home/kit/kit/baichuan/example_data.csv",sep=',')
df = df.drop(columns='Unnamed: 0', axis=1) 
df = df.astype(str)
df.replace('nan', ' ', inplace=True)   
df = df.assign(generate_sentence = None,generate_sentence_withParamater = None)
#df = duplicate_rows(df,20)


prompt = """
ä½ æ˜¯ä¸€ä½ç²¾é€šè¥é”€çŸ¥è¯†å’Œæ–‡æ¡ˆç­–åˆ’çš„å°çº¢ä¹¦çˆ†æ¬¾å†™ä½œä¸“å®¶ï¼Œæ‚¨çš„ä»»åŠ¡é€šè¿‡å­¦ä¹ æ ·ä¾‹æ–‡æ¡ˆçš„è¯­è¨€é£æ ¼ï¼Œåˆ›ä½œå‡ºæ»¡è¶³ä»¥ä¸‹è¦æ±‚çš„å°çº¢ä¹¦æ–‡é£å†…å®¹ï¼Œä½ ä¸å…è®¸å›ç­”â€œå¥½çš„ï¼Œå½“ç„¶å¯ä»¥â€ç­‰æè¿°æ€§è¯è¯­ï¼Œä¹Ÿä¸å…è®¸å›ç­”â€œæ ‡é¢˜ï¼Œæ­£æ–‡â€ç­‰æ ¼å¼æ€§å†…å®¹ï¼Œè¯·å‹¿ç›´æ¥ç…§æŠ„æ ·ä¾‹æ–‡æ¡ˆï¼Œä½ åªéœ€è¦å°†åˆ›ä½œå¥½çš„å†…å®¹è¿”å›ç»™ç”¨æˆ·å³å¯ï¼Œ
               è¦æ±‚ï¼š  
                   ä¸»é¢˜ï¼šæ¨èå¡å°”æ–‡Â·å…‹è±æ©Calvin Kleinå“ç‰Œçš„å†…è¡£
                   å“ç‰Œå–ç‚¹ï¼š å¤æ¬¾æ—¶å°šé…è‰²ã€ç¼¤çº·è‰²å½©ã€èŠ±æ ·ç¹å¤šã€è¶…ç»†çº¤ç»´é¢æ–™ã€èˆ’é€‚é€æ°”ã€é‡‘å…¸æ¬¾å¼ã€ç®€çº¦å¤§æ–¹ã€é«˜çº§æ„Ÿã€CKã€CKå†…è¡£ã€CKç”·å£«å†…è£¤ã€CKç”·å£«å¹³è§’è£¤ã€ç”·å£«ç¤¼ç‰©ã€ç”·å£«å†…è£¤æ¨èã€è¶…çº§èˆ’é€‚çš„ç”·å£«å†…è£¤ã€å¤å­£ç”·å£«å†…è£¤ã€å¤å­£å†°ä¸å†…è£¤ã€CKä»£è¨€äººç”°æŸ¾å›½ã€CKä»£è¨€äººJENNIEã€BLACKPINKã€BTSé˜²å¼¹å°‘å¹´å›¢ã€CKæ®µå®œæ©ã€CKä¸»æ‰“
                   å—ä¼—ç¾¤ä½“ï¼š 
                   å¹³å°æ–‡é£ï¼šå°çº¢ä¹¦
                   ä½¿ç”¨åœºæ™¯ï¼š 
                   æ¨èè§’åº¦ï¼š 
                   æ–‡æ¡ˆé£æ ¼ï¼š 
                   æ•…äº‹æ€§ï¼š 
                   å­—æ•°è¦æ±‚ï¼š 
                   è¥é”€ç›®çš„ï¼š 
                   å†™ä½œè¦æ±‚ï¼šä½¿ç”¨æƒŠå¹å·ã€è¡¨æƒ…ç¬¦å·ç­‰å¢åŠ æ–‡ç« æ´»åŠ›ï¼Œè¿ç”¨æ‚¬å¿µæ¥å¼•å‘è¯»è€…å¥½å¥‡å¿ƒ
                   å…¶ä»–è¦æ±‚ï¼š 
               æ ·ä¾‹æ–‡æ¡ˆï¼š
               ```
               å¤æ¬¾æ—¶å°šé…è‰²ï¼Œç¼¤çº·è‰²å½©ğŸƒï¼ŒèŠ±æ ·ç¹å¤š CKä¸»æ‰“ğŸ’¯è¶…ç»†çº¤ç»´é¢æ–™ï¼Œèˆ’é€‚é€æ°”âœ… é‡‘å…¸æ¬¾å¼ï¼Œç®€çº¦å¤§æ–¹ï¼Œé«˜çº§æ„Ÿæ‹‰ğŸˆµ
               ```
"""
for i in range(int(len(df))):
    s = prompt.replace(prompt[729:780],df.iloc[i,12])
    df.iloc[i,10] = str(df.iloc[i,10])
    s = s[:181] + df.iloc[i,0] + s[200:203] + df.iloc[i,1] + s[205:231] +  df.iloc[i,2] + s[383:408] +  df.iloc[i,4] + s[409:434] +  df.iloc[i,3] + s[437:462] +  df.iloc[i,5] + s[463:488]+  df.iloc[i,6] + s[489:514]+  df.iloc[i,7] + s[514:539]+  df.iloc[i,8] + s[539:565]+  df.iloc[i,9] + s[565:591]+  df.iloc[i,10] + s[591:672] + df.iloc[i,11] + s[672:]  
    messages = []
    messages.append({"role": "user", "content": s})
    response = model.chat(tokenizer, messages)
    response_withParamater = model_withParamater.chat(tokenizer_withParamater, messages)
    print(i,s,response,response_withParamater)
    df.iloc[i,15] = response
    df.iloc[i,16] = response_withParamater

output_file = 'output.csv'  
df.to_csv(output_file, index=False)

